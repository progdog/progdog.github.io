<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Apache Spark on That&#39;s it ! Code Snippets</title>
    <link>https://thats-it-code.com/categories/apache-spark/</link>
    <description>Recent content in Apache Spark on That&#39;s it ! Code Snippets</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Apr 2022 11:56:45 +0900</lastBuildDate><atom:link href="https://thats-it-code.com/categories/apache-spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ApacheSpark &gt;&gt; Schema</title>
      <link>https://thats-it-code.com/apachespark/apachespark__schemas/</link>
      <pubDate>Tue, 05 Apr 2022 11:56:45 +0900</pubDate>
      
      <guid>https://thats-it-code.com/apachespark/apachespark__schemas/</guid>
      <description>&lt;p&gt;In this article, we will talk about the schema of Spark DataFrame.&lt;br&gt;
&lt;strong&gt;A Spark schema is a definition of column names and types&lt;/strong&gt;.&lt;br&gt;
In Spark, the schema can also be inferred when reading the data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prepare data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Show schema of DataFrame&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Define the schema of data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load schema from json file&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://thats-it-code.com/img/apache-spark_schemas.png&#34; alt=&#34;[Apache Spark Schema] Introduction&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache Spark &gt;&gt; Create a Local Apache Spark Development Environment on Windows With Just Two Commands</title>
      <link>https://thats-it-code.com/apachespark/apachespark__create-a-local-apache-spark-development-environment-with-just-two-commands/</link>
      <pubDate>Sun, 03 Apr 2022 10:37:08 +0900</pubDate>
      
      <guid>https://thats-it-code.com/apachespark/apachespark__create-a-local-apache-spark-development-environment-with-just-two-commands/</guid>
      <description>&lt;p&gt;In this article, we will build a local development environment for PySpark and Jupyter Notebook using docker on windows.  Just two commands are needed to create a local environment for running Apache Spark application.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prerequisite&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create a local development environment&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test the enviroment&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://thats-it-code.com/img/apache-spark_localenv.png&#34; alt=&#34;[Apache Spark Local Env] Introduction&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apache Spark &gt;&gt; SparkSession, Create DataFrame</title>
      <link>https://thats-it-code.com/apachespark/apachespark__sparksession-and-create-dataframe/</link>
      <pubDate>Sat, 16 Oct 2021 18:03:30 +0900</pubDate>
      
      <guid>https://thats-it-code.com/apachespark/apachespark__sparksession-and-create-dataframe/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Apache Spark&lt;/strong&gt;, written in Scala, is a general-purpose distributed computing and data processing engine. &lt;strong&gt;Apache Spark&lt;/strong&gt; supports &lt;strong&gt;Scala, Java, Python, SQL and R&lt;/strong&gt; language.&lt;/p&gt;
&lt;p&gt;In this series, we will use &lt;strong&gt;Python&lt;/strong&gt; as main language.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://thats-it-code.com/img/spark_00001.png&#34; alt=&#34;[Apache Spark] Introduction&#34;&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
